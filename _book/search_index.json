[
["index.html", "Notes on ‘Deep Learning with R’ Chapter 1 Prerequisites 1.1 Tensors", " Notes on ‘Deep Learning with R’ Indrajeet Patil 2019-01-29 Chapter 1 Prerequisites Before starting with the examples included in this book, I found it useful to first clear up few basic concepts needed for data representation in R. 1.1 Tensors Deep learning involves data processing through layers of neural networks. So, of course, the first question is what’s the data structure and is it supported in R? The basic data structure in machine learning world is tensor, which is a generalization of vectors and matrices to higher dimensions (D). Tensors can be constructed in R using array function. There are no scalars (or 0D tensors) in R, but a vector of length one is conceptually similar to a scalar. # creating the data structure x0 &lt;- 2 # checking its attributes str(x0) ## num 2 dim(as.array(x0)) ## [1] 1 typeof(x0) ## [1] &quot;double&quot; Vectors have a single dimension (or they are 1D tensors). # creating the data structure x1 &lt;- c(2, -3, 5, 66) # checking its attributes str(x1) ## num [1:4] 2 -3 5 66 dim(as.array(x1)) ## [1] 4 typeof(x1) ## [1] &quot;double&quot; Note that both scalars and vectors are one-dimensional arrays in R. Matrices have two dimensions (or they are 2D tensors). # creating the data structure x2 &lt;- matrix(c(1:10), nrow = 2, ncol = 5) # checking its attributes str(x2) ## int [1:2, 1:5] 1 2 3 4 5 6 7 8 9 10 dim(as.array(x2)) ## [1] 2 5 typeof(x2) ## [1] &quot;integer&quot; If we were to imagine a cube with a collection of numbers along each of its axes, that’s what a 3D tensor would like. # creating the data structure x3 &lt;- array(data = c(1:24), dim = c(2, 3, 4)) # what it looks like # (it&#39;s like stacking 2 x 3 matrices on top of each other 4 times!) x3 ## , , 1 ## ## [,1] [,2] [,3] ## [1,] 1 3 5 ## [2,] 2 4 6 ## ## , , 2 ## ## [,1] [,2] [,3] ## [1,] 7 9 11 ## [2,] 8 10 12 ## ## , , 3 ## ## [,1] [,2] [,3] ## [1,] 13 15 17 ## [2,] 14 16 18 ## ## , , 4 ## ## [,1] [,2] [,3] ## [1,] 19 21 23 ## [2,] 20 22 24 # checking its attributes str(x3) ## int [1:2, 1:3, 1:4] 1 2 3 4 5 6 7 8 9 10 ... dim(x3) ## [1] 2 3 4 typeof(x3) ## [1] &quot;integer&quot; Each tensor has three key attributes- rank (or number of dimensions/axes): x3 is a 3D tensor so it has a rank of 3. shape: Confusingly, this refers to the number of dimensions (dim()) along each of these axes. For x3, this was 2, 3, 4. type: Type of data contained in the tensor. For x3, this was integer. So far we have been looking at made-up examples of tensors. Let’s have a look at the kind of data we will encounter in a typical ML workflow. We will look at the MNIST dataset contained in the keras library. library(keras) use_condaenv(&quot;r-tensorflow&quot;) ## Warning in normalizePath(path.expand(path), winslash, mustWork): ## path[1]=&quot;C:\\Users\\inp099\\AppData\\Local\\CONTIN~1\\ANACON~1\\envs\\rstudio/ ## python.exe&quot;: The system cannot find the file specified mnist &lt;- keras::dataset_mnist() ## Warning in normalizePath(path.expand(path), winslash, mustWork): ## path[1]=&quot;C:\\Users\\inp099\\AppData\\Local\\CONTIN~1\\ANACON~1\\envs\\rstudio/ ## python.exe&quot;: The system cannot find the file specified str(mnist) ## List of 2 ## $ train:List of 2 ## ..$ x: int [1:60000, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ... ## ..$ y: int [1:60000(1d)] 5 0 4 1 9 2 1 3 1 4 ... ## $ test :List of 2 ## ..$ x: int [1:10000, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ... ## ..$ y: int [1:10000(1d)] 7 2 1 0 4 1 4 9 5 9 ... "]
]
